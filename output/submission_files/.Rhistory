# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death)
data
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
data
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code)
data
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code)
data = data %>%
mutate(target = 1)
data
data %>%
filter(location_name = Michigan, quantile = "1%")
filter(location_name == Michigan, quantile == "1%")
data %>% filter(location_name == Michigan, quantile == "1%")
data %>% filter(location_name == "Michigan", quantile == "1%")
data %>% filter(location_name == "MI", quantile == "1%")
data %>% filter(location_name == "MI", quantile == "1%", target_end_date == "2020-04-27")
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
names(data)
head(data$InterventionScenario)
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
data
data %>% filter(state == "MI", quantile == "1%", target_end_date == "2020-04-27")
data %>% filter(location_name == "MI", quantile == "1%", target_end_date == "2020-04-27")
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code)
data = data %>%
mutate(target = 1)
# join the fips data and data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
rename(location = state_code) %>%
select(forecast_date, target, target_end_date, location, location_name, type, quantile, value) %>%
mutate(quantile = as.numeric(gsub("[\\%,]", "", quantile)))
filename = paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv")
write.csv(data, paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv"))
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
data
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code)
data = data %>%
mutate(target = 1)
# join the fips data and data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
rename(location = state_code) %>%
select(forecast_date, target, target_end_date, location, location_name, type, quantile, value) %>%
mutate(quantile = as.numeric(gsub("[\\%,]", "", quantile)))
head(data)
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code)
data
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code)
data = data %>%
mutate(target = 1)
data
data = data %>%
left_join(fips, by = c("location_name" = "state"))
data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
unique() %>%
)
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code)
data = data %>%
mutate(target = 1)
# join the fips data and data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
unique()
data
fips
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code) %>%
unique()
data = data %>%
mutate(target = 1)
# join the fips data and data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
rename(location = state_code) %>%
select(forecast_date, target, target_end_date, location, location_name, type, quantile, value) %>%
mutate(quantile = as.numeric(gsub("[\\%,]", "", quantile)))
data
rm(list = ls())
data = read_csv("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code) %>%
unique()
data = data %>%
mutate(target = 1)
# join the fips data and data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
rename(location = state_code) %>%
select(forecast_date, target, target_end_date, location, location_name, type, quantile, value) %>%
mutate(quantile = as.numeric(gsub("[\\%,]", "", quantile)))
filename = paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv")
write.csv(data, paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv"))
filename = paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv")
filename
setwd("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/submissionFiles")
setwd("~/Dropbox/ND_Coronavirus/analysis/cdc_forecasting/output/submissionFiles")
data = read_csv("../../output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code) %>%
unique()
data = data %>%
mutate(target = 1)
# join the fips data and data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
rename(location = state_code) %>%
select(forecast_date, target, target_end_date, location, location_name, type, quantile, value) %>%
mutate(quantile = as.numeric(gsub("[\\%,]", "", quantile)))
filename = paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv")
rm(list = ls())
data = read_csv("../../output/COVID19_FRED_forecasting_perkinslab_20200430.csv")
library(tigris)
# date that the forecast is being submitted
forecast_date = "2020-04-26"
# remove columns not needed for analysis
data = data %>%
filter(InterventionScenario == "ShelterAll") %>%
dplyr::select(state_name, Date, quantile, death) %>%
# only take forecasts after the forecast date
filter(Date > forecast_date) %>%
# rename columns to match format
rename(location_name = state_name, target_end_date = Date, value = death) %>%
mutate(forecast_date = forecast_date, type = "quantile")
# make state into fips
data(fips_codes)
fips = fips_codes %>%
dplyr::select(state, state_code) %>%
unique()
data = data %>%
mutate(target = 1)
# join the fips data and data
data = data %>%
left_join(fips, by = c("location_name" = "state")) %>%
rename(location = state_code) %>%
select(forecast_date, target, target_end_date, location, location_name, type, quantile, value) %>%
mutate(quantile = as.numeric(gsub("[\\%,]", "", quantile)))
filename = paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv")
write.csv(data, paste0(forecast_date, "-NotreDame-FRED-", "FRED.csv"))
####################################################################
# Annaliese Wieler
# February 14, 2019
################################################################
# clear environment
rm(list = ls())
# load packages
library(doParallel)
#####################################################################
# Set Numbers of Vectors, Numbers of People, and Interventions to Try
# number of clusters
nvec <-  seq(10,100,2)
# intervention levels
effect_vector <- seq(.01,.99,.01)
# number of years per trial
n.years = 3
# number of simulations for each cluster size/intervention pair
nsim = 100
# number of people in each simulation
n.people = 100
#####################################################################
# Set Ross-MacDonald and Wolbers parameters
# null log incidence (Wolbers)
mu <-  -3.4
# variances from Wolbers estimation
spat.var <-  .27 # within trial, constant for locations between years
temp.var <-  .53 # within trial, constant for year between locations
resid.var <- .74 # added into each individual cluster each year- all different
# parameters of disease transmission
a <-  .5
b <-  1
c <-  .5
g <-  .1
n <-  7
X <- 4.994419e-05
r <-  .25
alpha <-  1
dt <-  365
#################################################################
# Define the small functions
# Force of Infection
FOI = function(random_var) {
-log(1-exp(random_var))/365
}
# mosquito:human ratio
mval = function(FOI,a,b,c,X,g,n) {
(FOI*(g+a*c*X))/(b*c*X*a^2*exp(-g*n))
}
# attack rate functions
ARcontrol = function(FOI, dt){
1-exp(-FOI*dt)
}
ARtreatment = function(FOI, dt, effect.size){
1-exp(-(1-effect.size)*FOI*dt)
}
################################################
# function to make one single trial year
# for a single year, a vector of v values should be provided to it, such as
# rnorm(spat.var, sd = spat.var)
# spatial variation needs to be a vector of length n.clusters
single.year = function(n.clusters, intervention.effect, spatial.variance, year){
# make the data frame
data.y = expand.grid(cluster=1:n.clusters)
# add the year
data.y$year = year
# whether or not they were treated (binary)
data.y$trtd = c(rep(0, n.clusters/2), rep(1, n.clusters/2))
# make intervention effect
data.y$intervention = data.y$trtd * intervention.effect
# set temporal variance for this year
temporal.variance = rnorm(1, sd = temp.var)
# add in residual variance
residual.variance = rnorm(n.clusters, sd = resid.var)
# all variances and null added together
vars = temporal.variance + residual.variance + spatial.variance
# use poisson process to find number of seroconversions per cluster assuming intervention
data.y$sc = rpois(n.clusters, ((1-data.y$intervention) *
exp(mu + vars + log(n.people))))
# use poisson process to find number of seroconversions
data.y$scnoint = rpois(n.clusters, exp(mu + vars + log(n.people)))
return(data.y)
}
####################################################################
# simulates a full trial
single.trial = function(n.clusters, intervention.effect){
# define spatial variance for all years of this trial
spatial.variance = rnorm(n.clusters, sd = spat.var)
data1 = single.year(n.clusters, intervention.effect, spatial.variance,
year = 1)
data2 = single.year(n.clusters, intervention.effect, spatial.variance,
year = 2)
data3 = single.year(n.clusters, intervention.effect, spatial.variance,
year = 3)
# combine them all into one data frame
return(rbind(data1, data2, data3))
}
###################################################################
# do the statistics on it
single.trial.stat = function(n.clusters, intervention.effect){
# generate  data
data = single.trial(n.clusters, intervention.effect)
# start new data
newdata = expand.grid(cluster = unique(data$cluster))
# count the number of seroconversions of each cluster during all years
newdata$sc = sapply(1:n.clusters,function(c)sum(
data$sc[data$cluster==c]))
# indicate whether they were treated
newdata$trtd = data$trtd[1:n.clusters]
# count the number of seroconversions if treatment had no effect
newdata$sc_noint = sapply(1:n.clusters, function(c)sum(
data$scnoint[data$cluster==c]))
# number of person-years for each cluster
newdata$prsn.yr = rep(3 * 100, n.clusters)
# run glm on data
stat = glm(sc ~ trtd + offset(log(prsn.yr)),
data = newdata, family =
quasipoisson())
# validity, determined by whether a singificant impact is seen in
# situation where treatment is not considered
validity = glm(sc_noint ~ trtd +
offset(log(prsn.yr)),
data = newdata, family =
quasipoisson())
# extract the p-values for power and validity
pval = coef(summary(stat))['trtd','Pr(>|t|)']
pval.validity = coef(summary(validity))['trtd','Pr(>|t|)']
# return the two values
return(c(pval, pval.validity))
}
expand.grid(1:4)
nvec
effect_vector
1:nsim
expand.grid(nclusters = nvec, effect.size = effect_vector,
run = 1:nsim)
data = expand.grid(nclusters = nvec, effect.size = effect_vector,
run = 1:nsim)
nrow(data)
rep(NA, nrow(data))
data$pval = data$validity = rep(NA, nrow(data))
data
for (i in 1:5){
print(i)
}
1:nrow(data)
jj=1
data[jj,1]
data[jj, 2]
single.trial.stat(data[jj,1], data[jj, 2])
?sapply
c(2,3,4)
list(2,3,4)
list(c(2,3), 5, 1:5)
list(c(.03, .9), c(.9, .5))
result.list =list(c(.03, .9), c(.9, .5))
result.list[[2]]
result.list[[1]]
result.list[1]
data
